---
title: "a3_task3_leonardo_feitosa"
author: "Leonardo Feitosa"
date: "18/02/2021"
output: 
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidytext)
library(textdata)
library(pdftools)
library(ggrepel)
library(ggwordcloud)
library(here)
```


```{r, cache = TRUE}
## Read in the data 
sherlock_text <- pdf_text(here("data", "sherlock.pdf"))

sherlock_text_p50 <- sherlock_text[50]
```



```{r}
## Wrangling text
sherlock_text_tidy <- data.frame(sherlock_text) %>% 
  mutate(text_full = str_split(sherlock_text, pattern = "\\r\n")) %>% 
  unnest(text_full) %>% 
  mutate(text_full = str_squish(text_full))
```




```{r}
## Tidying the data
sherlock_df <- sherlock_text_tidy %>% 
  slice(-(1:34)) %>% 
  mutate(part = case_when(
    str_detect(text_full, "Part") ~ text_full,
    TRUE ~ NA_character_
  )) %>% 
  fill(part) %>% 
  separate(col = part, into = c("pt", "no"), sep = " ") %>% 
  mutate(no = as.numeric(no))
```



```{r}
## Counts of words
sherlock_tokens <- sherlock_df %>% 
  unnest_tokens(word, text_full) %>% 
  select(-sherlock_text)

# Counts
sherlock_wordcount <- sherlock_tokens %>% 
  count(no, word)
```



```{r, message = FALSE}
## Removing stop words
sherlock_nonstop_words <- sherlock_tokens %>% 
  anti_join(stop_words)

nonstop_counts <- sherlock_nonstop_words %>% 
  count(no, word)
```



```{r}
## Counts of most frequent words by part
top_10_words <- nonstop_counts %>% 
  group_by(no) %>% 
  arrange(-n) %>% 
  slice(1:10)

# Plot
ggplot(data = top_10_words, aes(x = word, y = n)) +
  geom_col(fill = "darkgreen",
           alpha = 0.8,
           color = "aliceblue") +
  facet_wrap(~ no, scales = "free") +
  labs(x = "Words",
       y = "Number per chapter",
       title = "Top 10 words per part in Sherlock Holmes by Sir Arthur Conan Doyle") +
  coord_flip() +
  theme_bw() +
  theme(panel.grid = element_blank(),
        axis.title = element_text(size = 12, face = "bold", color = "black"),
        axis.text = element_text(size = 10, color = "gray19"),
        strip.background = element_rect(fill = "white"),
        strip.text = element_text(size = 11, face = "bold", color = "black"))
```



```{r, include = FALSE}
## Wordcloud
# Make this wordcloud by chapter and then put them together with patchwork
#sherlock_cloud <- ggplot(data = nonstop_counts,
#                        aes(label = word)) +
# geom_text_wordcloud(aes(color = n, size = n), shape = "diamond") +
#  scale_size_area(max_size = 6) +
#  scale_color_gradientn(colors = c("darkgreen", "blue", "purple")) +
#  theme_bw()

#sherlock_cloud
```


```{r}
## NRC
sherlock_nrc <- sherlock_nonstop_words %>% 
  inner_join(get_sentiments("nrc"))
```

```{r}
sherlock_nrc_counts <- sherlock_nrc %>% 
  count(no, sentiment) %>% 
  mutate(sentiment = case_when(
    sentiment == "trust" ~ "Trust",
    sentiment == "surprise" ~ "Surprise",
    sentiment == "sadness" ~ "Sadness",
    sentiment == "positive" ~ "Positive",
    sentiment == "negative" ~ "Negative",
    sentiment == "joy" ~ "Joy",
    sentiment == "fear" ~ "Fear",
    sentiment == "disgust" ~ "Disgust",
    sentiment == "anticipation" ~ "Anticipation",
    sentiment == "anger" ~ "Anger"
  ))

# Make the finalized plot
ggplot(data = sherlock_nrc_counts, aes(x = sentiment, y = n)) +
  geom_col(fill = "lightcoral",
           color = "black",
           alpha = 0.8) +
  facet_wrap(~ no) +
  labs(x = "Sentiment based on the NRC lexicon",
       y = "Number of words",
       title = "Distribution of sentiments across the 12 parts of Sir Arthur Conan Doyle's Sherlock Holmes book") +
  coord_flip() +
  theme_bw() +
  theme(axis.title = element_text(size = 12, face = "bold", color = "black"),
        axis.text = element_text(size = 11, color = "gray18"),
        strip.background = element_rect(fill = "white"),
        strip.text = element_text(size = 12, color = "black"),
        panel.grid = element_blank())
```



#### Citation: Doyle, AC (1892) The Adventures of Sherlock Holmes. *INCLUDE PUBLISHER*


















